{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f001010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Locally\n",
      "Configuration:\n",
      " Environment: Local\n",
      " Project Root: ..\n",
      " Data Model: ../docs/AIMS Data Model.txt\n",
      " Parquet Dir: ../data/Samples_LH_Bronze_Aims_26_parquet\n",
      "Using aims_data_platform v1.0.2 from /home/sanmi/Documents/HS2/HS2_PROJECTS_2025/1_AIMS_LOCAL_2026/aims_data_platform/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Detect Environment\n",
    "try:\n",
    "    from notebookutils import mssparkutils\n",
    "    IS_FABRIC = True\n",
    "    print(\"Running in Microsoft Fabric\")\n",
    "except ImportError:\n",
    "    IS_FABRIC = False\n",
    "    print(\"Running Locally\")\n",
    "\n",
    "# 2. Define Paths based on Environment\n",
    "if IS_FABRIC:\n",
    "    # Fabric: Use Lakehouse Paths (OneLake mounted path)\n",
    "    BASE_DIR = Path(\"/lakehouse/default/Files\")\n",
    "    \n",
    "    # Try to load .env from the Lakehouse Files root if it exists\n",
    "    env_path = BASE_DIR / \".env\"\n",
    "    if env_path.exists():\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        print(f\"Loaded configuration from {env_path}\")\n",
    "    \n",
    "    PROJECT_ROOT = BASE_DIR\n",
    "    DATA_MODEL_FILE = BASE_DIR / \"docs/AIMS Data Model.txt\"\n",
    "    PARQUET_DIR = BASE_DIR / os.getenv(\"BRONZE_PATH\", \"data/Samples_LH_Bronze_Aims_26_parquet\")\n",
    "    \n",
    "else:\n",
    "    # Local: Use .env or defaults\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Prioritize local development path in sys.path\n",
    "    project_root_local = Path.cwd().parent.resolve()\n",
    "    if str(project_root_local) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root_local))\n",
    "        \n",
    "    PROJECT_ROOT = Path(\"..\")\n",
    "    DATA_MODEL_FILE = PROJECT_ROOT / \"docs/AIMS Data Model.txt\"\n",
    "    PARQUET_DIR = PROJECT_ROOT / \"data/Samples_LH_Bronze_Aims_26_parquet\"\n",
    "\n",
    "print(f\"Configuration:\\n Environment: {'Fabric' if IS_FABRIC else 'Local'}\")\n",
    "print(f\" Project Root: {PROJECT_ROOT}\")\n",
    "print(f\" Data Model: {DATA_MODEL_FILE}\")\n",
    "print(f\" Parquet Dir: {PARQUET_DIR}\")\n",
    "\n",
    "import aims_data_platform\n",
    "importlib.reload(aims_data_platform)\n",
    "print(f\"Using aims_data_platform v{aims_data_platform.__version__} from {aims_data_platform.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d730b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aims_data_platform.schema_reconciliation import (\n",
    "    parse_data_model, \n",
    "    analyze_comparison, \n",
    "    analyze_extra_files,\n",
    "    format_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2171d",
   "metadata": {},
   "source": [
    "# AIMS Data Platform: Bird's Eye View Insights\n",
    "\n",
    "This notebook provides a high-level overview of the AIMS data ecosystem, generating key information, statistics, and insights based on the current data model and physical storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605e7b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Model and Analyzing Parquet Files...\n",
      "Analysis Complete.\n"
     ]
    }
   ],
   "source": [
    "# Load Data Model and Run Analysis\n",
    "print(\"Loading Data Model and Analyzing Parquet Files...\")\n",
    "tables = parse_data_model(DATA_MODEL_FILE)\n",
    "df_results, modeled_files = analyze_comparison(tables, PARQUET_DIR)\n",
    "df_extra = analyze_extra_files(modeled_files, PARQUET_DIR)\n",
    "\n",
    "# Ensure numeric types for analysis\n",
    "df_results['Rows'] = pd.to_numeric(df_results['Rows'], errors='coerce').fillna(0)\n",
    "print(\"Analysis Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ec041",
   "metadata": {},
   "source": [
    "## 1. Key Information (5 Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d7c410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5 Key Information Points ---\n",
      "1. Project Environment        : Local\n",
      "2. Data Source Path           : ../data/Samples_LH_Bronze_Aims_26_parquet\n",
      "3. Data Model Reference       : ../docs/AIMS Data Model.txt\n",
      "4. Analysis Timestamp         : 2025-12-07 20:24:55\n",
      "5. Library Version            : 1.0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 5 Key Information Points ---\")\n",
    "info = {\n",
    "    \"1. Project Environment\": \"Fabric\" if IS_FABRIC else \"Local\",\n",
    "    \"2. Data Source Path\": str(PARQUET_DIR),\n",
    "    \"3. Data Model Reference\": str(DATA_MODEL_FILE),\n",
    "    \"4. Analysis Timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"5. Library Version\": aims_data_platform.__version__\n",
    "}\n",
    "for k, v in info.items():\n",
    "    print(f\"{k:<30}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f0219",
   "metadata": {},
   "source": [
    "## 2. Key Statistics (10 Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea2af0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10 Key Statistics ---\n",
      "1. Total Tables in Model:       29\n",
      "2. Total Parquet Files Found:   68\n",
      "3. Total Rows (Approx):         70,147,779\n",
      "4. Average Rows per Table:      2,805,911\n",
      "5. Missing Files:               4\n",
      "6. Extra (Unmodeled) Files:     43\n",
      "7. Schema Mismatches:           21\n",
      "8. Perfect Schema Matches:      23\n",
      "9. Total Columns Defined:       722\n",
      "10. Schema Health Score:        79.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 10 Key Statistics ---\")\n",
    "\n",
    "# Calculations\n",
    "total_tables_model = len(tables)\n",
    "total_parquet_files = len(list(PARQUET_DIR.glob('*.parquet')))\n",
    "total_rows = df_results['Rows'].sum()\n",
    "missing_files = len(df_results[df_results['Status'] == 'MISSING FILE'])\n",
    "mismatches = len(df_results[df_results['Status'] == 'MISMATCH'])\n",
    "perfect_matches = len(df_results[df_results['Status'].str.contains('MATCH')])\n",
    "extra_files = len(df_extra)\n",
    "avg_rows = total_rows / (total_tables_model - missing_files) if (total_tables_model - missing_files) > 0 else 0\n",
    "total_cols_model = sum(len(cols) for cols in tables.values())\n",
    "health_score = (perfect_matches / total_tables_model) * 100 if total_tables_model > 0 else 0\n",
    "\n",
    "stats = [\n",
    "    f\"1. Total Tables in Model:       {total_tables_model}\",\n",
    "    f\"2. Total Parquet Files Found:   {total_parquet_files}\",\n",
    "    f\"3. Total Rows (Approx):         {int(total_rows):,}\",\n",
    "    f\"4. Average Rows per Table:      {int(avg_rows):,}\",\n",
    "    f\"5. Missing Files:               {missing_files}\",\n",
    "    f\"6. Extra (Unmodeled) Files:     {extra_files}\",\n",
    "    f\"7. Schema Mismatches:           {mismatches}\",\n",
    "    f\"8. Perfect Schema Matches:      {perfect_matches}\",\n",
    "    f\"9. Total Columns Defined:       {total_cols_model}\",\n",
    "    f\"10. Schema Health Score:        {health_score:.1f}%\"\n",
    "]\n",
    "for s in stats:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5361105",
   "metadata": {},
   "source": [
    "## 3. Automated Insights (20 Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a9191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20 Automated Insights ---\n",
      "1. Largest Table: 'AssetAttributes' with 60,090,986 rows.\n",
      "2. Top 5 tables contain 99% of total data volume.\n",
      "3. There are 1 tables that exist but have 0 rows (Empty Tables).\n",
      "4. Schema Mismatch detected in 'Routes' (Missing/Extra columns).\n",
      "5. 4 tables defined in the model are completely missing from the storage.\n",
      "6. Found 43 files not in the model, suggesting undocumented data sources.\n",
      "7. Example unmodeled file: 'aims_activitydates.parquet'\n",
      "8. Widest Table: 'AssetAttributes' with 79 columns.\n",
      "9. Narrowest Table: 'InformationPackages' with 1 columns.\n",
      "10. Average column count per table is 24.\n",
      "11. Data Density: 1031584 rows per file on average.\n",
      "12. Model Coverage: 86% of modeled tables exist.\n",
      "13. The dataset is dominated by a few large tables.\n",
      "14. Significant schema drift detected (21 tables).\n",
      "15. Storage efficiency: Parquet format is being used (columnar storage).\n",
      "16. Environment is Local, affecting path resolution.\n",
      "17. Library 'aims_data_platform' v1.0.2 is driving this analysis.\n",
      "18. 23 tables are 'Gold Standard' (Perfect Match).\n",
      "19. 6 tables require attention (Missing or Mismatch).\n",
      "20. System Audit Columns (KINO) are likely missing in some tables.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 20 Automated Insights ---\")\n",
    "insights = []\n",
    "\n",
    "# Volume Insights\n",
    "top_5_vol = df_results.sort_values('Rows', ascending=False).head(5)\n",
    "insights.append(f\"1. Largest Table: '{top_5_vol.iloc[0]['Table']}' with {int(top_5_vol.iloc[0]['Rows']):,} rows.\")\n",
    "insights.append(f\"2. Top 5 tables contain {int(top_5_vol['Rows'].sum() / total_rows * 100) if total_rows > 0 else 0}% of total data volume.\")\n",
    "empty_tables = df_results[(df_results['Rows'] == 0) & (df_results['Status'] != 'MISSING FILE')]\n",
    "insights.append(f\"3. There are {len(empty_tables)} tables that exist but have 0 rows (Empty Tables).\")\n",
    "\n",
    "# Schema Insights\n",
    "if mismatches > 0:\n",
    "    worst_mismatch = df_results[df_results['Status']=='MISMATCH'].iloc[0]\n",
    "    insights.append(f\"4. Schema Mismatch detected in '{worst_mismatch['Table']}' (Missing/Extra columns).\")\n",
    "else:\n",
    "    insights.append(\"4. No schema mismatches detected across all files.\")\n",
    "\n",
    "insights.append(f\"5. {missing_files} tables defined in the model are completely missing from the storage.\")\n",
    "\n",
    "# Extra Files\n",
    "if extra_files > 0:\n",
    "    insights.append(f\"6. Found {extra_files} files not in the model, suggesting undocumented data sources.\")\n",
    "    insights.append(f\"7. Example unmodeled file: '{df_extra.iloc[0]['File Name']}'\")\n",
    "else:\n",
    "    insights.append(\"6. No extra files found; storage is clean relative to model.\")\n",
    "    insights.append(\"7. Model fully covers all files in directory.\")\n",
    "\n",
    "# Column Insights\n",
    "col_counts = {t: len(c) for t, c in tables.items()}\n",
    "if col_counts:\n",
    "    max_col_table = max(col_counts, key=col_counts.get)\n",
    "    min_col_table = min(col_counts, key=col_counts.get)\n",
    "    insights.append(f\"8. Widest Table: '{max_col_table}' with {col_counts[max_col_table]} columns.\")\n",
    "    insights.append(f\"9. Narrowest Table: '{min_col_table}' with {col_counts[min_col_table]} columns.\")\n",
    "    insights.append(f\"10. Average column count per table is {int(sum(col_counts.values())/len(col_counts))}.\")\n",
    "else:\n",
    "    insights.append(\"8. No tables found in model.\")\n",
    "    insights.append(\"9. No tables found in model.\")\n",
    "    insights.append(\"10. No columns found in model.\")\n",
    "\n",
    "# Derived Insights\n",
    "insights.append(f\"11. Data Density: {int(total_rows/total_parquet_files) if total_parquet_files else 0} rows per file on average.\")\n",
    "insights.append(f\"12. Model Coverage: {int((total_tables_model - missing_files)/total_tables_model * 100) if total_tables_model else 0}% of modeled tables exist.\")\n",
    "\n",
    "# Structural/Generic Insights\n",
    "insights.append(f\"13. The dataset is {'dominated by a few large tables' if (top_5_vol['Rows'].sum() / total_rows) > 0.8 else 'fairly distributed'}.\")\n",
    "insights.append(f\"14. {'Significant' if mismatches > total_tables_model*0.1 else 'Minor'} schema drift detected ({mismatches} tables).\")\n",
    "insights.append(f\"15. Storage efficiency: Parquet format is being used (columnar storage).\")\n",
    "insights.append(f\"16. Environment is {'Cloud-based (Fabric)' if IS_FABRIC else 'Local'}, affecting path resolution.\")\n",
    "insights.append(f\"17. Library 'aims_data_platform' v{aims_data_platform.__version__} is driving this analysis.\")\n",
    "insights.append(f\"18. {perfect_matches} tables are 'Gold Standard' (Perfect Match).\")\n",
    "insights.append(f\"19. {len(df_results) - perfect_matches} tables require attention (Missing or Mismatch).\")\n",
    "insights.append(f\"20. System Audit Columns (KINO) are likely {'present' if mismatches == 0 else 'missing in some tables'}.\")\n",
    "\n",
    "for i in insights:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b0980",
   "metadata": {},
   "source": [
    "## Visual Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Status Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "status_counts = df_results['Status'].value_counts()\n",
    "sns.barplot(x=status_counts.index, y=status_counts.values, palette='viridis')\n",
    "plt.title('Distribution of Table Status')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Status')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aims_data_platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
